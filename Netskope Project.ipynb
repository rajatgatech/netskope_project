{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install nltk\n",
    "# !pip install langdetect\n",
    "# !pip install scikit-learn gensim\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Job Role</th>\n",
       "      <th>Job Function</th>\n",
       "      <th>Job Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manager-Cybersecurity</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager, Information Security</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User Experience Analyst</td>\n",
       "      <td>Development</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Contributor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network Specialist</td>\n",
       "      <td>Networking</td>\n",
       "      <td>IT</td>\n",
       "      <td>Contributor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Director of Privacy and Compliance</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title              Job Role Job Function  \\\n",
       "0               Manager-Cybersecurity  Information Security           IT   \n",
       "1       Manager, Information Security  Information Security           IT   \n",
       "2             User Experience Analyst           Development  Engineering   \n",
       "3                  Network Specialist            Networking           IT   \n",
       "4  Director of Privacy and Compliance  Information Security           IT   \n",
       "\n",
       "     Job Level  \n",
       "0      Manager  \n",
       "1      Manager  \n",
       "2  Contributor  \n",
       "3  Contributor  \n",
       "4     Director  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Historical Lead Records.csv', encoding='latin1')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make title column lowercase\n",
    "df['Title'] = df['Title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m grouped \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(most_frequent)\n\u001b[0;32m      9\u001b[0m grouped\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df, grouped, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_most_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1304\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1302\u001b[0m gba \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, [func], args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1304\u001b[0m     result \u001b[38;5;241m=\u001b[39m gba\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:166\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg):\n\u001b[0;32m    169\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(arg)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:355\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m     new_res \u001b[38;5;241m=\u001b[39m colg\u001b[38;5;241m.\u001b[39maggregate(\n\u001b[0;32m    352\u001b[0m         arg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m    353\u001b[0m     )\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m     new_res \u001b[38;5;241m=\u001b[39m colg\u001b[38;5;241m.\u001b[39maggregate(arg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    356\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[0;32m    357\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend(index)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:238\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m--> 238\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:316\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[0;32m    315\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m--> 316\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:269\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:288\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    287\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m--> 288\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(obj, f)\n\u001b[0;32m    289\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:285\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_agg_general\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    284\u001b[0m     func \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mis_builtin_func(func)\n\u001b[1;32m--> 285\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    287\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(obj, f)\n",
      "Cell \u001b[1;32mIn[52], line 3\u001b[0m, in \u001b[0;36mmost_frequent\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmost_frequent\u001b[39m(x):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mvalue_counts()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:1015\u001b[0m, in \u001b[0;36mIndexOpsMixin.value_counts\u001b[1;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_counts\u001b[39m(\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     dropna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m    937\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;124;03m    Return a Series containing counts of unique values.\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;124;03m    Name: count, dtype: int64\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mvalue_counts(\n\u001b[0;32m   1016\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1017\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1018\u001b[0m         ascending\u001b[38;5;241m=\u001b[39mascending,\n\u001b[0;32m   1019\u001b[0m         normalize\u001b[38;5;241m=\u001b[39mnormalize,\n\u001b[0;32m   1020\u001b[0m         bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m   1021\u001b[0m         dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   1022\u001b[0m     )\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:885\u001b[0m, in \u001b[0;36mvalue_counts\u001b[1;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_arraylike(values)\n\u001b[1;32m--> 885\u001b[0m     keys, counts \u001b[38;5;241m=\u001b[39m value_counts_arraylike(values, dropna)\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[0;32m    887\u001b[0m         keys \u001b[38;5;241m=\u001b[39m keys\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:926\u001b[0m, in \u001b[0;36mvalue_counts_arraylike\u001b[1;34m(values, dropna, mask)\u001b[0m\n\u001b[0;32m    923\u001b[0m original \u001b[38;5;241m=\u001b[39m values\n\u001b[0;32m    924\u001b[0m values \u001b[38;5;241m=\u001b[39m _ensure_data(values)\n\u001b[1;32m--> 926\u001b[0m keys, counts \u001b[38;5;241m=\u001b[39m htable\u001b[38;5;241m.\u001b[39mvalue_count(values, dropna, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(original\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;66;03m# datetime, timedelta, or period\u001b[39;00m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropna:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#data relableing to most frequent F/R/L\n",
    "def most_frequent(x):\n",
    "    if not x.empty and len(x.value_counts()) > 0:\n",
    "        return x.value_counts().index[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "grouped = df.groupby('Title').agg(most_frequent)\n",
    "grouped.reset_index(inplace=True)\n",
    "\n",
    "merged_df = pd.merge(df, grouped, on='Title', suffixes=('', '_most_frequent'))\n",
    "\n",
    "merged_df.drop(['Job Role', 'Job Function', 'Job Level'], axis=1, inplace=True)\n",
    "\n",
    "merged_df.rename(columns={'Job Role_most_frequent': 'Job Role', 'Job Function_most_frequent': 'Job Function', 'Job Level_most_frequent': 'Job Level'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865671\n",
      "1616\n",
      "864055\n"
     ]
    }
   ],
   "source": [
    "#1616 rows are completely empty\n",
    "before_dropping = df.shape[0]\n",
    "empty_rows= df.isna().all(axis=1).sum()\n",
    "df = df.dropna(how='all')\n",
    "after_dropping = df.shape[0]\n",
    "\n",
    "\n",
    "print (before_dropping)\n",
    "print (empty_rows)\n",
    "print (after_dropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_mark = df['Title'].str.contains('\\?').sum()\n",
    "question_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #replacing all question marks with empty strings\n",
    "df['Title'] = df['Title'].str.replace('?', '')\n",
    "question_mark1 = df['Title'].str.contains('\\?').sum()\n",
    "question_mark1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852981"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['Title'])\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(str(text)) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "def filter_english_titles(df):\n",
    "    return df[df['Title'].apply(is_english)]\n",
    "\n",
    "num_jobs = 4\n",
    "chunks = np.array_split(df, num_jobs)\n",
    "df_filtered_chunks = Parallel(n_jobs=num_jobs)(\n",
    "    delayed(filter_english_titles)(chunk) for chunk in chunks\n",
    ")\n",
    "df_filtered = pd.concat(df_filtered_chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the cleaning steps above take a while to run, output df_filtered to csv\n",
    "#df_filtered.to_csv('df_filtered.csv', index=False)\n",
    "df_filtered = pd.read_csv('df_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {'IT Audit / IT Compliance': 'Risk/Legal/Compliance',\n",
    "               'IT': 'IT',\n",
    "               'Engineering': 'Engineering',\n",
    "               'Purchasing': 'Procurement',\n",
    "               'Legal': 'Risk/Legal/Compliance',\n",
    "               'Finance': 'Non-ICP',\n",
    "               'Marketing': 'Non-ICP',\n",
    "               'Sales': 'Non-ICP',\n",
    "               'Unknown': 'Non-ICP',\n",
    "               'Facilities': 'Non-ICP',\n",
    "               'Human Resource': 'Non-ICP',\n",
    "               'Management': 'Non-ICP',\n",
    "               'Services': 'Non-ICP',\n",
    "               'Operations': 'Non-ICP',\n",
    "               'Administration': 'Non-ICP',\n",
    "               'Corporate': 'Non-ICP',\n",
    "               'Support': 'Non-ICP',\n",
    "               'Education': 'Non-ICP',\n",
    "               'Public Sector': 'Non-ICP',\n",
    "               'Procurement': 'Procurement',\n",
    "               'Medical': 'Non-ICP',\n",
    "               'Other': 'Non-ICP',\n",
    "               'IT Audit / IT Compliance': 'Risk/Legal/Compliance',\n",
    "               'Information Security': 'IT',\n",
    "               'IT - Security': 'IT',\n",
    "               'Help Desk / Desktop Services': 'IT',\n",
    "               'Information Technology': 'IT',\n",
    "               'Infrastructure': 'Non-ICP',\n",
    "               'Customer Service / Support': 'Non-ICP',\n",
    "               'Emerging Technology / Innovation': 'IT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for Job Role within IT function\n",
    "replacements_role = {'Information Security': 'Information Security',\n",
    "               'information security': 'Information Security',\n",
    "               'Networking': 'Networking',\n",
    "               'IT General': 'IT General',\n",
    "               'None Technical': 'IT General',\n",
    "               'Help Desk': 'IT General',\n",
    "               'Governance Risk Compliance': 'IT General',\n",
    "               'Program Management': 'IT General',\n",
    "               'Data': 'IT General',\n",
    "               'IT Facilities': 'IT General',\n",
    "               'Operations': 'IT General',\n",
    "               'Communications': 'IT General',\n",
    "               'Integration': 'IT General',\n",
    "               'Vendor Management': 'IT General',\n",
    "               'Training': 'IT General',\n",
    "               'Business Continuity': 'IT General',\n",
    "               'Other': 'IT General',\n",
    "               'Development': 'Development',\n",
    "                'Security': 'Information Security',\n",
    "                    'Business Systems': 'Systems'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for Job Level within all ICP functions\n",
    "replacements_level = {'Manager': 'Manager',\n",
    "                     'Contributor': 'Contributor',\n",
    "                      'contributor': 'Contributor',\n",
    "                     'Director': 'Director',\n",
    "                     'C-Level': 'C-level',\n",
    "                      'C-level': 'C-level',\n",
    "                     'Executive': 'Executive',\n",
    "                     'Unknown': pd.NA,\n",
    "                      'Non-Manager': 'Contributor',\n",
    "                      'VP-level': 'Executive',\n",
    "                      'VP-Level': 'Executive',\n",
    "                      'Decision maker': 'Manager',\n",
    "                      'Team Lead': 'Manager',\n",
    "                      'VP/Director': 'Director',\n",
    "                      'Engineer/Admin': 'Contributor',\n",
    "                      'CxO': 'C-level',\n",
    "                      'VP': 'Executive',\n",
    "                      'Director / C-Level': 'C-level',\n",
    "                      'Individual Contributor': 'Contributor',\n",
    "                      'Director Level': 'Director',\n",
    "                      'contribtuor': 'Contributor',\n",
    "                      'Management': 'Manager',\n",
    "                      'Director of Enterprise Cloud Business': 'Director',\n",
    "                      'Admin': 'Contributor'\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['Job Function'] = df_filtered['Job Function'].replace(replacements)\n",
    "df_filtered['Job Function'] = df_filtered['Job Function'].fillna('Non-ICP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IT', 'Engineering', 'Procurement', 'Risk/Legal/Compliance',\n",
       "       'Non-ICP'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['Job Function'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['Job Level'] = df_filtered['Job Level'].replace(replacements_level)\n",
    "df_filtered.loc[df_filtered['Job Function']=='Non-ICP', 'Job Level'] = pd.NA\n",
    "df_filtered['Job Level'] = df_filtered['Job Level'].fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_role(row):\n",
    "    if pd.isnull(row['Job Function']): \n",
    "        return 'N/A'\n",
    "    elif 'IT' not in row['Job Function']:\n",
    "        return 'N/A'\n",
    "    else:\n",
    "        return row['Job Role']\n",
    "\n",
    "df_filtered['Job Role'] = df_filtered.apply(replace_role, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Job Role</th>\n",
       "      <th>Job Function</th>\n",
       "      <th>Job Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manager-cybersecurity</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manager, information security</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user experience analyst</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Contributor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>network specialist</td>\n",
       "      <td>Networking</td>\n",
       "      <td>IT</td>\n",
       "      <td>Contributor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>director of privacy and compliance</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title              Job Role Job Function  \\\n",
       "0               manager-cybersecurity  Information Security           IT   \n",
       "1       manager, information security  Information Security           IT   \n",
       "2             user experience analyst                   N/A  Engineering   \n",
       "3                  network specialist            Networking           IT   \n",
       "4  director of privacy and compliance  Information Security           IT   \n",
       "\n",
       "     Job Level  \n",
       "0      Manager  \n",
       "1      Manager  \n",
       "2  Contributor  \n",
       "3  Contributor  \n",
       "4     Director  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#non_it = df_filtered[~df_filtered['Job Function'].str.contains('IT')]\n",
    "#non_it.head()\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Manager', 'Contributor', 'Director', 'C-level', 'Executive', <NA>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['Job Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any stop words from the titles\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "df['Title'] = df['Title'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "#Some more preprocessing that will remove punctuations. \n",
    "tokenised_titles = df['Title'].apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Title_Tokens</th>\n",
       "      <th>Job Role</th>\n",
       "      <th>Job Function</th>\n",
       "      <th>Job Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manager-cybersecurity</td>\n",
       "      <td>[manager, cybersecurity]</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manager, information security</td>\n",
       "      <td>[manager, information, security]</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user experience analyst</td>\n",
       "      <td>[user, experience, analyst]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Contributor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>network specialist</td>\n",
       "      <td>[network, specialist]</td>\n",
       "      <td>Networking</td>\n",
       "      <td>IT</td>\n",
       "      <td>Contributor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>director privacy compliance</td>\n",
       "      <td>[director, privacy, compliance]</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title                      Title_Tokens  \\\n",
       "0          manager-cybersecurity          [manager, cybersecurity]   \n",
       "1  manager, information security  [manager, information, security]   \n",
       "2        user experience analyst       [user, experience, analyst]   \n",
       "3             network specialist             [network, specialist]   \n",
       "4    director privacy compliance   [director, privacy, compliance]   \n",
       "\n",
       "               Job Role Job Function    Job Level  \n",
       "0  Information Security           IT      Manager  \n",
       "1  Information Security           IT      Manager  \n",
       "2                   N/A  Engineering  Contributor  \n",
       "3            Networking           IT  Contributor  \n",
       "4  Information Security           IT     Director  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add the tokens as a column in df\n",
    "df.insert(1, 'Title_Tokens', tokenised_titles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459757, 9898370)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize and train model\n",
    "model = gensim.models.Word2Vec(window=2,min_count=1, workers=4)\n",
    "model.build_vocab(df['Title_Tokens'])#this is a required step before training the model \n",
    "model.train(df['Title_Tokens'], total_examples=model.corpus_count, epochs=model.epochs) #default vector_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('director', 0.7374807000160217),\n",
       " ('leader', 0.6985123753547668),\n",
       " ('supervisor', 0.6763476133346558),\n",
       " ('mgr', 0.6627412438392639),\n",
       " ('manger', 0.6499350666999817),\n",
       " ('lead', 0.6399224996566772),\n",
       " ('specialist', 0.6316721439361572),\n",
       " ('head', 0.6070242524147034),\n",
       " ('analyst', 0.6062723994255066),\n",
       " ('coordinator', 0.6008464097976685)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"manager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('analysts', 0.7701191306114197),\n",
       " ('specialist', 0.7637343406677246),\n",
       " ('intern', 0.6739217638969421),\n",
       " ('ofms', 0.6251246929168701),\n",
       " ('technician', 0.6185065507888794),\n",
       " ('enginner', 0.6131559014320374),\n",
       " ('spec', 0.6095673441886902),\n",
       " ('engineer', 0.6072471141815186),\n",
       " ('manager', 0.6062723398208618),\n",
       " ('manger', 0.5876338481903076)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('noc', 0.6242579817771912),\n",
       " ('datacenter', 0.582085132598877),\n",
       " ('ip', 0.5743829011917114),\n",
       " ('networks', 0.5661808848381042),\n",
       " ('installation', 0.5608255863189697),\n",
       " ('operation', 0.5464958548545837),\n",
       " ('networking', 0.545594334602356),\n",
       " ('voice', 0.5450116395950317),\n",
       " ('carrier', 0.5387231707572937),\n",
       " ('grid', 0.5374865531921387)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Title_Tokens</th>\n",
       "      <th>Title_Vec</th>\n",
       "      <th>Job Role</th>\n",
       "      <th>Job Function</th>\n",
       "      <th>Job Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manager-cybersecurity</td>\n",
       "      <td>[manager, cybersecurity]</td>\n",
       "      <td>[-0.48963156, 1.7655406, -0.9755714, -1.016060...</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manager, information security</td>\n",
       "      <td>[manager, information, security]</td>\n",
       "      <td>[-0.39355576, 3.932649, -1.0444752, -1.3062502...</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user experience analyst</td>\n",
       "      <td>[user, experience, analyst]</td>\n",
       "      <td>[-0.9645748, 2.373046, -1.3231623, -2.7005827,...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Contributor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>network specialist</td>\n",
       "      <td>[network, specialist]</td>\n",
       "      <td>[-0.06601313, 2.3728542, -1.2169973, 0.4478888...</td>\n",
       "      <td>Networking</td>\n",
       "      <td>IT</td>\n",
       "      <td>Contributor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>director privacy compliance</td>\n",
       "      <td>[director, privacy, compliance]</td>\n",
       "      <td>[-0.16704276, 3.9424748, -0.60280246, -0.21131...</td>\n",
       "      <td>Information Security</td>\n",
       "      <td>IT</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title                      Title_Tokens  \\\n",
       "0          manager-cybersecurity          [manager, cybersecurity]   \n",
       "1  manager, information security  [manager, information, security]   \n",
       "2        user experience analyst       [user, experience, analyst]   \n",
       "3             network specialist             [network, specialist]   \n",
       "4    director privacy compliance   [director, privacy, compliance]   \n",
       "\n",
       "                                           Title_Vec              Job Role  \\\n",
       "0  [-0.48963156, 1.7655406, -0.9755714, -1.016060...  Information Security   \n",
       "1  [-0.39355576, 3.932649, -1.0444752, -1.3062502...  Information Security   \n",
       "2  [-0.9645748, 2.373046, -1.3231623, -2.7005827,...                   N/A   \n",
       "3  [-0.06601313, 2.3728542, -1.2169973, 0.4478888...            Networking   \n",
       "4  [-0.16704276, 3.9424748, -0.60280246, -0.21131...  Information Security   \n",
       "\n",
       "  Job Function    Job Level  \n",
       "0           IT      Manager  \n",
       "1           IT      Manager  \n",
       "2  Engineering  Contributor  \n",
       "3           IT  Contributor  \n",
       "4           IT     Director  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#below function creates a vector for a title by adding the vector of each word in it\n",
    "def get_title_vec(title_tokens):\n",
    "    # create a list of vectors of all the tokens in a title\n",
    "    vectors = [ model.wv[token] for token in title_tokens]\n",
    "    #sum all the vectors in the list\n",
    "    return np.sum(vectors, axis=0)\n",
    "\n",
    "title_vecs = df['Title_Tokens'].map(get_title_vec)\n",
    "#Add title vecs as a column in df \n",
    "df.insert(2, 'Title_Vec', title_vecs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First set up DTM\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "# Vectorize titles \n",
    "vec = CountVectorizer(token_pattern = r'\\b[a-zA-Z]{3,}[a-zA-Z]*\\b',\n",
    "                      max_df=0.5,\n",
    "                      lowercase=True, \n",
    "                      stop_words=list(stops), \n",
    "                      max_features=1000, ngram_range=(1,2)) \n",
    "dtm = vec.fit_transform(df['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-4e2d9926eaa8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  it_function['Job Role'] = it_function['Job Role'].replace(replacements_role)\n",
      "<ipython-input-13-4e2d9926eaa8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  it_function['Job Role'] = it_function['Job Role'].fillna('IT General')\n"
     ]
    }
   ],
   "source": [
    "# Create DTM for titles that are in IT\n",
    "it_function = df[df['Job Function'].str.contains('IT')]\n",
    "it_function['Job Role'] = it_function['Job Role'].replace(replacements_role)\n",
    "it_function['Job Role'] = it_function['Job Role'].fillna('IT General')\n",
    "\n",
    "dtm_it = vec.fit_transform(it_function['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DTM for levels that are in ICP\n",
    "icp_titles = df[df['Job Function']!='Non-ICP']\n",
    "icp_titles = icp_titles.dropna(subset=['Job Level'])\n",
    "dtm_icp = vec.fit_transform(icp_titles['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX,validX,trainy,validy = train_test_split(dtm, df['Job Function'],train_size=0.80,random_state=123)\n",
    "trainX_role, validX_role, trainy_role, validy_role = train_test_split(dtm_it, it_function['Job Role'], train_size=0.80, random_state=123)\n",
    "trainX_level, validX_level, trainy_level, validy_level = train_test_split(dtm_icp, icp_titles['Job Level'], train_size=0.80, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with Bayes Naive Classifier to determine Job Function \n",
    "from sklearn.naive_bayes import GaussianNB as NBC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "nbc = NBC()\n",
    "rf = RFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to tune for NBC\n",
    "nbc_params = {'var_smoothing': [0.1, 0.5, 1.0, 2.0]}\n",
    "\n",
    "rf_params = {'n_estimators':[10],\n",
    "             'criterion':['gini','log_loss'],\n",
    "             'max_depth':[None,10],\n",
    "             'min_samples_split':[2,5], # required to split\n",
    "             'max_features':[None,'sqrt','log2'],\n",
    "             'max_samples':[None,0.10,0.75],\n",
    "             'random_state':[123]\n",
    "            }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with hold-out sample for best fit of this model:...\n",
      "\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "          Engineering       0.91      0.95      0.93      9123\n",
      "                   IT       0.97      0.98      0.97     88874\n",
      "              Non-ICP       0.89      0.80      0.84     11682\n",
      "          Procurement       0.76      0.81      0.79       222\n",
      "Risk/Legal/Compliance       0.96      0.75      0.84       176\n",
      "\n",
      "             accuracy                           0.96    110077\n",
      "            macro avg       0.90      0.86      0.88    110077\n",
      "         weighted avg       0.96      0.96      0.96    110077\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################## JOB FUNCTION ######################\n",
    "final_mods_function = []\n",
    "for mod,params in zip([RFC()],[rf_params]):\n",
    "#for mod,params in zip([NBC(), RFC()],[nbc_params, rf_params]): # zip creates a list of tuples we can use to iterate\n",
    "    rand_search = RandomizedSearchCV(mod,params, # positional arguments, model and parameter grid\n",
    "                                     n_iter=50,\n",
    "                                     scoring='f1_macro', \n",
    "                                     cv=5,\n",
    "                                     random_state=123,\n",
    "                                     n_jobs=-1)\n",
    "    \n",
    "    rand_search.fit(trainX.toarray(),trainy)\n",
    "    print(f\"Classification Report with hold-out sample for best fit of this model:...\\n\")\n",
    "    print(type(mod))\n",
    "    print(classification_report(validy,rand_search.predict(validX.toarray())))\n",
    "    print(\"------------------------------------------------------\")\n",
    "    final_mods_function.append(rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator for Random Forest for JOB FUNCTION: RandomForestClassifier(max_features='sqrt', n_estimators=10, random_state=123) \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best estimator for Random Forest for JOB FUNCTION: {final_mods_function[0].best_estimator_} \\n\\n\\n\")\n",
    "rand_search_function = final_mods_function[0].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0ad6aadf9944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_params_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrand_search_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_params_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'best_model_job_function.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "best_params_function = rand_search_function.best_params_\n",
    "joblib.dump(best_params_function, 'best_model_job_function.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with hold-out sample for best fit of this model:...\n",
      "\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "         Development       0.78      0.76      0.77      2067\n",
      "          IT General       0.82      0.64      0.72     14611\n",
      "Information Security       0.90      0.90      0.90     40182\n",
      "          Networking       0.86      0.96      0.91     29988\n",
      "             Systems       0.82      0.74      0.77      2019\n",
      "\n",
      "            accuracy                           0.87     88867\n",
      "           macro avg       0.84      0.80      0.81     88867\n",
      "        weighted avg       0.87      0.87      0.87     88867\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################## JOB ROLE FOR IT ONLY ######################\n",
    "final_mods_role = []\n",
    "for mod,params in zip([RFC()],[rf_params]):\n",
    "#for mod,params in zip([NBC(), RFC()],[nbc_params, rf_params]): # zip creates a list of tuples we can use to iterate\n",
    "    rand_search = RandomizedSearchCV(mod,params, # positional arguments, model and parameter grid\n",
    "                                     n_iter=50,\n",
    "                                     scoring='f1_macro', \n",
    "                                     cv=5,\n",
    "                                     random_state=123,\n",
    "                                     n_jobs=-1)\n",
    "    \n",
    "    rand_search.fit(trainX_role.toarray(),trainy_role)\n",
    "    print(f\"Classification Report with hold-out sample for best fit of this model:...\\n\")\n",
    "    print(type(mod))\n",
    "    print(classification_report(validy_role,rand_search.predict(validX_role.toarray())))\n",
    "    print(\"------------------------------------------------------\")\n",
    "    final_mods_role.append(rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator for Random Forest for JOB ROLE FOR IT ONLY: RandomForestClassifier(max_features=None, n_estimators=10, random_state=123) \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best estimator for Random Forest for JOB ROLE FOR IT ONLY: {final_mods_role[0].best_estimator_} \\n\\n\\n\")\n",
    "#rand_search_role = final_mods_role[0].best_estimator_\n",
    "#best_params_role = rand_search_role.best_params_\n",
    "#joblib.dump(best_params_role, 'best_model_job_role.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lwilson\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with hold-out sample for best fit of this model:...\n",
      "\n",
      "<class 'sklearn.naive_bayes.GaussianNB'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     C-level       0.66      0.92      0.77      9596\n",
      " Contributor       0.85      0.91      0.88     34166\n",
      "    Director       0.89      0.95      0.92     19362\n",
      "   Executive       0.91      0.52      0.66     12198\n",
      "     Manager       0.94      0.84      0.89     21266\n",
      "\n",
      "    accuracy                           0.85     96588\n",
      "   macro avg       0.85      0.83      0.82     96588\n",
      "weighted avg       0.87      0.85      0.85     96588\n",
      "\n",
      "------------------------------------------------------\n",
      "Classification Report with hold-out sample for best fit of this model:...\n",
      "\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     C-level       0.94      0.94      0.94      9596\n",
      " Contributor       0.95      0.96      0.95     34166\n",
      "    Director       0.97      0.97      0.97     19362\n",
      "   Executive       0.92      0.87      0.89     12198\n",
      "     Manager       0.96      0.96      0.96     21266\n",
      "\n",
      "    accuracy                           0.95     96588\n",
      "   macro avg       0.95      0.94      0.94     96588\n",
      "weighted avg       0.95      0.95      0.95     96588\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "final_mods_level = []\n",
    "################## JOB LEVEL FOR ICP ONLY ######################\n",
    "for mod,params in zip([NBC(), RFC()],[nbc_params, rf_params]): # zip creates a list of tuples we can use to iterate\n",
    "    rand_search = RandomizedSearchCV(mod,params, # positional arguments, model and parameter grid\n",
    "                                     n_iter=50,\n",
    "                                     scoring='f1_macro', \n",
    "                                     cv=5,\n",
    "                                     random_state=123,\n",
    "                                     n_jobs=-1)\n",
    "    \n",
    "    rand_search.fit(trainX_level.toarray(),trainy_level)\n",
    "    print(f\"Classification Report with hold-out sample for best fit of this model:...\\n\")\n",
    "    print(type(mod))\n",
    "    print(classification_report(validy_level,rand_search.predict(validX_level.toarray())))\n",
    "    print(\"------------------------------------------------------\")\n",
    "    final_mods_level.append(rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator for NBC for JOB LEVEL FOR ICP ONLY: GaussianNB(var_smoothing=0.1) \n",
      "\n",
      "\n",
      "\n",
      "Best estimator for Random Forest for JOB LEVEL FOR ICP ONLY: RandomForestClassifier(max_features='sqrt', n_estimators=10, random_state=123) \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best estimator for NBC for JOB LEVEL FOR ICP ONLY: {final_mods_level[0].best_estimator_} \\n\\n\\n\")\n",
    "print(f\"Best estimator for Random Forest for JOB LEVEL FOR ICP ONLY: {final_mods_level[1].best_estimator_} \\n\\n\\n\")\n",
    "\n",
    "#rand_search_level = final_mods_level[1].best_estimator_\n",
    "#best_params_level = rand_search_level.best_params_\n",
    "#joblib.dump(best_params_level, 'best_model_job_level.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once final models are decided, need to create code to input CSV file with Record ID, Job Title\n",
    "# Output will be Record ID, Job Title, Job Function, Job Role, Job Level  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
